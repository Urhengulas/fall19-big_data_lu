{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bptk-py\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "from elasticsearch import Elasticsearch\n",
    "import os.path\n",
    "from src.config.conf import width,height\n",
    "from src.setup import setup_model\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Batch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'es_node1', 'port': 9200}])\n",
    "\n",
    "\n",
    "car_list=[\"1_car\",\"2_car\",\"3_car\"]\n",
    "keys=['id','time_start','time_end','revenue','cost','profit']\n",
    "\n",
    "data={\"time\":0}\n",
    "\n",
    "for car in car_list:\n",
    "    data[car]={\n",
    "        \"sum_revenue\":0,\n",
    "        \"sum_cost\":0,\n",
    "        \"profit\":0\n",
    "    }\n",
    "    \n",
    "# initiale the data pickle\n",
    "\n",
    "with open(\"csv/data.pickle\",'wb') as data_file_obj:\n",
    "    pickle.dump(data,data_file_obj)   \n",
    "\n",
    "sleep_time=60\n",
    "time_delta=1440\n",
    "last_batch_processing_time=0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    # read the time\n",
    "    time_file_object = open(\"csv/sim_time.pickle\",'rb')  \n",
    "    current_time = pickle.load(time_file_object)\n",
    "\n",
    "    if current_time>=last_batch_processing_time+time_delta:\n",
    "        \n",
    "        # read the data\n",
    "        data_file_object = open (\"csv/data.pickle\",'rb')\n",
    "        data=pickle.load(data_file_object)\n",
    "        data[\"time\"]=last_batch_processing_time+time_delta\n",
    "    \n",
    "        for car in car_list:\n",
    "            time_from=last_batch_processing_time+1\n",
    "            time_to=last_batch_processing_time+time_delta+1\n",
    "               \n",
    "            profit_result=es.search(index=car,body={\"size\": 0,\n",
    "                \"aggs\" : {\n",
    "                    \"sum_profit\" : {\n",
    "                        \"date_range\": {\n",
    "                            \"field\": \"time\",\n",
    "                            \"ranges\": [\n",
    "                                { \"from\": time_from,\n",
    "                                  \"to\": time_to } \n",
    "                            ]\n",
    "                        },\n",
    "                        \"aggs\": {\n",
    "                            \"sum_cost\": {\n",
    "                              \"sum\": {\n",
    "                                \"field\": \"cost\"\n",
    "                              }\n",
    "                            },\n",
    "                            \"sum_revenue\":{\n",
    "                              \"sum\":{\n",
    "                                \"field\":\"revenue\"\n",
    "                              }\n",
    "                            },\n",
    "                            \"profit\": {\n",
    "                                \"bucket_script\": {\n",
    "                                    \"buckets_path\": {\n",
    "                                      \"sumRev\": \"sum_revenue\",\n",
    "                                      \"sumCost\": \"sum_cost\"\n",
    "                                    },\n",
    "                                    \"script\": \"params.sumRev - params.sumCost\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }})\n",
    "\n",
    "            for result in [\"sum_revenue\",\"sum_cost\",\"profit\"]:\n",
    "                if result in profit_result[\"aggregations\"][\"sum_profit\"][\"buckets\"][0].keys():\n",
    "                    data[car][result]+=(profit_result['aggregations']['sum_profit']['buckets'][0][result]['value'])\n",
    "                else:\n",
    "                    data[car][result]+=0\n",
    "        \n",
    "        # write the data\n",
    "        \n",
    "        with open(\"csv/data.pickle\",'wb') as data_file_obj:\n",
    "            pickle.dump(data,data_file_obj)   \n",
    "    \n",
    "        last_batch_processing_time+=time_delta\n",
    "    else:        \n",
    "        time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
